---
layout: post
title: Selenium으로 네이버에서 크보 중계 데이터 긁어오기 4
category: KBO, 중계긁기
tags:
- KBO
- 스크래핑
- python
date: 2025-06-17 00:36 +0900
---
이전 포스트까지 해서 이제 한 경기의 중계 페이지가 주어졌을 때 해당 경기의 이닝별 중계 데이터들을 긁어서 합쳐오는 코드가 만들어졌다. 이번에는 여기에 더해 중계 페이지 데이터 외에 다른 페이지에서도 쓸만한 데이터를 가져오는 것을 해두려 한다.

다른 페이지에서 긁어올 만한 정보는 라인업 페이지의 선발 라인업 및 후보, 불펜 선수들의 목록과, 기록 페이지의 경기 결과 파트가 있다. 이 두 페이지의 정보도 중계 데이터와 비슷하게 페이지 이동 시 데이터를 json파일로 받아온다. 그러니 중계 데이터를 긁어오는 코드를 활용하여 쉽게 만들 수 있을 것이다.

![선발라인업](/assets/img/post_img/Selenium_4/선발_라인업.png)
_라인업 페이지의 선발 라인업 예시. 밑에는 후보 야수 및 불펜 투수 목록이 있다._

![경기기록](/assets/img/post_img/Selenium_4/경기_기록.png)
_경기 기록 예시. 자주 볼 수 있는 기록페이지이다._

라인업 데이터는 path의 마지막이 preview, 기록 데이터는 record로 끝나기 때문에 이를 이용해서 긁어올 수 있다. 결과적으로 우리가 짜는 코드는 경기 페이지에서 라인업 탭 -> 중계 탭 -> 기록 탭을 이동하면서 필요한 데이터들을 받아오는 구조가 된다. 이를 위해 우선은 페이지 내에서 탭을 이동하는 것부터 시작해야 한다.

다시 html 소스를 뒤져보면서 필요한 탭 버튼을 찾아내는 코드를 짜보자. 

```python
def find_tab_button(self):
    main_section = self.driver.find_element(By.CSS_SELECTOR, 'div[class^="Home_main_section"]')
    game_panel = main_section.find_element(By.CSS_SELECTOR, 'section[class^="Home_game_panel"]')
    game_tab = game_panel.find_element(By.CSS_SELECTOR, 'ul[class^="GameTab_tab_list"]')
    tab_buttons = game_tab.find_elements(By.CSS_SELECTOR, 'button')

    return tab_buttons
```

여기서 관심있는 탭은 라인업, 중계, 기록 탭이다. 좀 더 안정성있게 하려면 버튼에 표기된 이름들을 확인해보면 되겠지만 버튼 순서가 그렇게 휙휙 바뀌게 네이버가 패치할 것 같진 않으니 지금은 순서만 가지고 작업을 해도 괜찮을 것 같다. (다만 다이나믹 페이지라 가로가 짧은 모바일 버전과 PC버전에서 구성이 다르니 이 부분만 신경써주자.) 이렇게 찾아낸 버튼을 가지고 라인업 데이터와 기록 데이터를 가져오는 짜보면 다음과 같다.

```python
def get_lineup_data(self, lineup_btn):
    del self.driver.requests
    ActionChains(self.driver).move_to_element(lineup_btn).click(lineup_btn).perform()
    time.sleep(1)
    for request in self.driver.requests:
        if 'preview' in request.path:
            body = request.response.body.decode('euc-kr')
            lineup_data = json.loads(body)
    
    return lineup_data

def get_result_data(self, result_btn):
    del self.driver.requests
    ActionChains(self.driver).move_to_element(result_btn).click(result_btn).perform()
    time.sleep(1)
    for request in self.driver.requests:
        if 'record' in request.path:
            body = request.response.body.decode('utf-8')
            record_data = json.loads(body)
    
    return record_data
```

버튼을 눌러 탭을 이동하는 사항을 반영하여 이전에 작성한 이닝 데이터 받아오는 코드도 다음과 같이 수정된다.

```python
def get_inning_data(self, relay_btn):
    ActionChains(self.driver).move_to_element(relay_btn).click(relay_btn).perform()
    time.sleep(1)
    ...
```

편의를 위해 세 코드를 한번에 실행할 수 있도록 묶어주는 함수를 하나 작성해두자.

```python
def get_game_data(self, game_url):
    self.driver.get(game_url)
    tab_buttons = self.find_tab_button()
    lineup_data = self.get_lineup_data(tab_buttons[2])
    inning_data = self.get_inning_data(tab_buttons[3])
    result_data = self.get_result_data(tab_buttons[6])

    return lineup_data, inning_data, result_data
```

메인이 되는 경기 주소를 받아서 원하는 데이터를 받아온 다음, 모두 반환하는 구조의 함수이다. 버튼을 넣어주는 곳에 있는 매직 넘버는 신경쓰인다면 나중에 따로 문자 형태로 바꿔줄 수도 있다.

테스트 코드는 다음과 같다.

```python
if __name__ == "__main__":
    scrapper = Scrapper()
    game_url = "https://m.sports.naver.com/game/20250419NCHH02025"

    ld, ind, rd = scrapper.get_game_data(game_url)
    
    with open('lineup.json', 'w') as tgtfile:
        json.dump(ld, tgtfile, ensure_ascii= False, indent = 4)
    with open('inning.json', 'w') as tgtfile:
        json.dump(ind, tgtfile, ensure_ascii= False, indent = 4)
    with open('record.json', 'w') as tgtfile:
        json.dump(rd, tgtfile, ensure_ascii= False, indent = 4)

    os.system("pause")
```

테스트코드를 실행하면 우리가 원하던 데이터들을 모두 저장하는 것을 확인할 수 있다!